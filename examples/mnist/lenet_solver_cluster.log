I0621 21:59:32.959298 18138 caffe.cpp:185] Using GPUs 0
I0621 21:59:32.966318 18138 caffe.cpp:190] GPU 0: GeForce GTX 980
I0621 21:59:33.162303 18138 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.001
display: 100
max_iter: 100000
lr_policy: "fixed"
momentum: 0.9
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "examples/mnist/lenet_train_test_cluster.prototxt"
momentum2: 0.999
type: "Adam"
I0621 21:59:33.162446 18138 solver.cpp:91] Creating training net from net file: examples/mnist/lenet_train_test_cluster.prototxt
I0621 21:59:33.162847 18138 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0621 21:59:33.162864 18138 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer cluster_cluster
I0621 21:59:33.162873 18138 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer prob
I0621 21:59:33.162876 18138 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0621 21:59:33.162987 18138 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cluster_shortpath"
  type: "InnerProduct"
  bottom: "pool2"
  top: "cluster_shortpath"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 250
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "cluster_cluster"
  type: "Clustering"
  bottom: "pool2"
  bottom: "label"
  top: "cluster_cluster"
  include {
    phase: TRAIN
  }
  clustering_param {
    k: 20
    total_class: 10
    num_output: 250
    lambda: 0.001
    branch: true
    across_class: true
    data_size: 20000
  }
}
layer {
  name: "cluster"
  type: "Concat"
  bottom: "cluster_cluster"
  bottom: "cluster_shortpath"
  top: "cluster"
}
layer {
  name: "dropout"
  type: "Dropout"
  bottom: "cluster"
  top: "cluster"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "cluster"
  top: "cluster"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "cluster"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0621 21:59:33.163082 18138 layer_factory.hpp:77] Creating layer mnist
I0621 21:59:33.163616 18138 net.cpp:91] Creating Layer mnist
I0621 21:59:33.163632 18138 net.cpp:399] mnist -> data
I0621 21:59:33.163657 18138 net.cpp:399] mnist -> label
I0621 21:59:33.164364 18145 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_train_lmdb
I0621 21:59:33.174134 18138 data_layer.cpp:41] output data size: 256,1,28,28
I0621 21:59:33.176326 18138 net.cpp:141] Setting up mnist
I0621 21:59:33.176352 18138 net.cpp:148] Top shape: 256 1 28 28 (200704)
I0621 21:59:33.176358 18138 net.cpp:148] Top shape: 256 (256)
I0621 21:59:33.176363 18138 net.cpp:156] Memory required for data: 803840
I0621 21:59:33.176375 18138 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0621 21:59:33.176395 18138 net.cpp:91] Creating Layer label_mnist_1_split
I0621 21:59:33.176409 18138 net.cpp:425] label_mnist_1_split <- label
I0621 21:59:33.176429 18138 net.cpp:399] label_mnist_1_split -> label_mnist_1_split_0
I0621 21:59:33.176441 18138 net.cpp:399] label_mnist_1_split -> label_mnist_1_split_1
I0621 21:59:33.176491 18138 net.cpp:141] Setting up label_mnist_1_split
I0621 21:59:33.176502 18138 net.cpp:148] Top shape: 256 (256)
I0621 21:59:33.176508 18138 net.cpp:148] Top shape: 256 (256)
I0621 21:59:33.176512 18138 net.cpp:156] Memory required for data: 805888
I0621 21:59:33.176517 18138 layer_factory.hpp:77] Creating layer conv1
I0621 21:59:33.176537 18138 net.cpp:91] Creating Layer conv1
I0621 21:59:33.176542 18138 net.cpp:425] conv1 <- data
I0621 21:59:33.176594 18138 net.cpp:399] conv1 -> conv1
I0621 21:59:33.304103 18138 net.cpp:141] Setting up conv1
I0621 21:59:33.304141 18138 net.cpp:148] Top shape: 256 20 24 24 (2949120)
I0621 21:59:33.304147 18138 net.cpp:156] Memory required for data: 12602368
I0621 21:59:33.304167 18138 layer_factory.hpp:77] Creating layer pool1
I0621 21:59:33.304182 18138 net.cpp:91] Creating Layer pool1
I0621 21:59:33.304188 18138 net.cpp:425] pool1 <- conv1
I0621 21:59:33.304196 18138 net.cpp:399] pool1 -> pool1
I0621 21:59:33.304268 18138 net.cpp:141] Setting up pool1
I0621 21:59:33.304286 18138 net.cpp:148] Top shape: 256 20 12 12 (737280)
I0621 21:59:33.304293 18138 net.cpp:156] Memory required for data: 15551488
I0621 21:59:33.304301 18138 layer_factory.hpp:77] Creating layer conv2
I0621 21:59:33.304332 18138 net.cpp:91] Creating Layer conv2
I0621 21:59:33.304342 18138 net.cpp:425] conv2 <- pool1
I0621 21:59:33.304354 18138 net.cpp:399] conv2 -> conv2
I0621 21:59:33.305862 18138 net.cpp:141] Setting up conv2
I0621 21:59:33.305877 18138 net.cpp:148] Top shape: 256 50 8 8 (819200)
I0621 21:59:33.305882 18138 net.cpp:156] Memory required for data: 18828288
I0621 21:59:33.305894 18138 layer_factory.hpp:77] Creating layer pool2
I0621 21:59:33.305902 18138 net.cpp:91] Creating Layer pool2
I0621 21:59:33.305907 18138 net.cpp:425] pool2 <- conv2
I0621 21:59:33.305913 18138 net.cpp:399] pool2 -> pool2
I0621 21:59:33.305966 18138 net.cpp:141] Setting up pool2
I0621 21:59:33.305980 18138 net.cpp:148] Top shape: 256 50 4 4 (204800)
I0621 21:59:33.305984 18138 net.cpp:156] Memory required for data: 19647488
I0621 21:59:33.305989 18138 layer_factory.hpp:77] Creating layer pool2_pool2_0_split
I0621 21:59:33.305995 18138 net.cpp:91] Creating Layer pool2_pool2_0_split
I0621 21:59:33.306000 18138 net.cpp:425] pool2_pool2_0_split <- pool2
I0621 21:59:33.306007 18138 net.cpp:399] pool2_pool2_0_split -> pool2_pool2_0_split_0
I0621 21:59:33.306015 18138 net.cpp:399] pool2_pool2_0_split -> pool2_pool2_0_split_1
I0621 21:59:33.306067 18138 net.cpp:141] Setting up pool2_pool2_0_split
I0621 21:59:33.306080 18138 net.cpp:148] Top shape: 256 50 4 4 (204800)
I0621 21:59:33.306085 18138 net.cpp:148] Top shape: 256 50 4 4 (204800)
I0621 21:59:33.306089 18138 net.cpp:156] Memory required for data: 21285888
I0621 21:59:33.306094 18138 layer_factory.hpp:77] Creating layer cluster_shortpath
I0621 21:59:33.306107 18138 net.cpp:91] Creating Layer cluster_shortpath
I0621 21:59:33.306113 18138 net.cpp:425] cluster_shortpath <- pool2_pool2_0_split_0
I0621 21:59:33.306120 18138 net.cpp:399] cluster_shortpath -> cluster_shortpath
I0621 21:59:33.307713 18138 net.cpp:141] Setting up cluster_shortpath
I0621 21:59:33.307728 18138 net.cpp:148] Top shape: 256 250 (64000)
I0621 21:59:33.307732 18138 net.cpp:156] Memory required for data: 21541888
I0621 21:59:33.307741 18138 layer_factory.hpp:77] Creating layer cluster_cluster
I0621 21:59:33.307754 18138 net.cpp:91] Creating Layer cluster_cluster
I0621 21:59:33.307759 18138 net.cpp:425] cluster_cluster <- pool2_pool2_0_split_1
I0621 21:59:33.307765 18138 net.cpp:425] cluster_cluster <- label_mnist_1_split_0
I0621 21:59:33.307770 18138 net.cpp:399] cluster_cluster -> cluster_cluster
I0621 21:59:33.352013 18138 net.cpp:141] Setting up cluster_cluster
I0621 21:59:33.352049 18138 net.cpp:148] Top shape: 256 250 (64000)
I0621 21:59:33.352054 18138 net.cpp:156] Memory required for data: 21797888
I0621 21:59:33.352183 18138 layer_factory.hpp:77] Creating layer cluster
I0621 21:59:33.352203 18138 net.cpp:91] Creating Layer cluster
I0621 21:59:33.352211 18138 net.cpp:425] cluster <- cluster_cluster
I0621 21:59:33.352217 18138 net.cpp:425] cluster <- cluster_shortpath
I0621 21:59:33.352224 18138 net.cpp:399] cluster -> cluster
I0621 21:59:33.352262 18138 net.cpp:141] Setting up cluster
I0621 21:59:33.352277 18138 net.cpp:148] Top shape: 256 500 (128000)
I0621 21:59:33.352284 18138 net.cpp:156] Memory required for data: 22309888
I0621 21:59:33.352289 18138 layer_factory.hpp:77] Creating layer dropout
I0621 21:59:33.352298 18138 net.cpp:91] Creating Layer dropout
I0621 21:59:33.352303 18138 net.cpp:425] dropout <- cluster
I0621 21:59:33.352309 18138 net.cpp:386] dropout -> cluster (in-place)
I0621 21:59:33.352352 18138 net.cpp:141] Setting up dropout
I0621 21:59:33.352367 18138 net.cpp:148] Top shape: 256 500 (128000)
I0621 21:59:33.352375 18138 net.cpp:156] Memory required for data: 22821888
I0621 21:59:33.352381 18138 layer_factory.hpp:77] Creating layer relu1
I0621 21:59:33.352388 18138 net.cpp:91] Creating Layer relu1
I0621 21:59:33.352392 18138 net.cpp:425] relu1 <- cluster
I0621 21:59:33.352399 18138 net.cpp:386] relu1 -> cluster (in-place)
I0621 21:59:33.352746 18138 net.cpp:141] Setting up relu1
I0621 21:59:33.352759 18138 net.cpp:148] Top shape: 256 500 (128000)
I0621 21:59:33.352764 18138 net.cpp:156] Memory required for data: 23333888
I0621 21:59:33.352769 18138 layer_factory.hpp:77] Creating layer ip2
I0621 21:59:33.352778 18138 net.cpp:91] Creating Layer ip2
I0621 21:59:33.352783 18138 net.cpp:425] ip2 <- cluster
I0621 21:59:33.352789 18138 net.cpp:399] ip2 -> ip2
I0621 21:59:33.353299 18138 net.cpp:141] Setting up ip2
I0621 21:59:33.353312 18138 net.cpp:148] Top shape: 256 10 (2560)
I0621 21:59:33.353317 18138 net.cpp:156] Memory required for data: 23344128
I0621 21:59:33.353324 18138 layer_factory.hpp:77] Creating layer loss
I0621 21:59:33.353332 18138 net.cpp:91] Creating Layer loss
I0621 21:59:33.353337 18138 net.cpp:425] loss <- ip2
I0621 21:59:33.353343 18138 net.cpp:425] loss <- label_mnist_1_split_1
I0621 21:59:33.353350 18138 net.cpp:399] loss -> loss
I0621 21:59:33.353366 18138 layer_factory.hpp:77] Creating layer loss
I0621 21:59:33.353982 18138 net.cpp:141] Setting up loss
I0621 21:59:33.353996 18138 net.cpp:148] Top shape: (1)
I0621 21:59:33.354001 18138 net.cpp:151]     with loss weight 1
I0621 21:59:33.354022 18138 net.cpp:156] Memory required for data: 23344132
I0621 21:59:33.354025 18138 net.cpp:217] loss needs backward computation.
I0621 21:59:33.354030 18138 net.cpp:217] ip2 needs backward computation.
I0621 21:59:33.354034 18138 net.cpp:217] relu1 needs backward computation.
I0621 21:59:33.354038 18138 net.cpp:217] dropout needs backward computation.
I0621 21:59:33.354043 18138 net.cpp:217] cluster needs backward computation.
I0621 21:59:33.354050 18138 net.cpp:217] cluster_cluster needs backward computation.
I0621 21:59:33.354059 18138 net.cpp:217] cluster_shortpath needs backward computation.
I0621 21:59:33.354068 18138 net.cpp:217] pool2_pool2_0_split needs backward computation.
I0621 21:59:33.354075 18138 net.cpp:217] pool2 needs backward computation.
I0621 21:59:33.354084 18138 net.cpp:217] conv2 needs backward computation.
I0621 21:59:33.354090 18138 net.cpp:217] pool1 needs backward computation.
I0621 21:59:33.354099 18138 net.cpp:217] conv1 needs backward computation.
I0621 21:59:33.354113 18138 net.cpp:219] label_mnist_1_split does not need backward computation.
I0621 21:59:33.354122 18138 net.cpp:219] mnist does not need backward computation.
I0621 21:59:33.354133 18138 net.cpp:261] This network produces output loss
I0621 21:59:33.354154 18138 net.cpp:274] Network initialization done.
I0621 21:59:33.354539 18138 solver.cpp:181] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test_cluster.prototxt
I0621 21:59:33.354579 18138 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0621 21:59:33.354591 18138 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer cluster_cluster
I0621 21:59:33.354703 18138 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cluster_shortpath"
  type: "InnerProduct"
  bottom: "pool2"
  top: "cluster_shortpath"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 250
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "cluster_cluster"
  type: "Clustering"
  bottom: "pool2"
  top: "cluster_cluster"
  include {
    phase: TEST
  }
  clustering_param {
    k: 20
    total_class: 10
    num_output: 250
    lambda: 0.001
    branch: true
    across_class: true
    data_size: 20000
  }
}
layer {
  name: "cluster"
  type: "Concat"
  bottom: "cluster_cluster"
  bottom: "cluster_shortpath"
  top: "cluster"
}
layer {
  name: "dropout"
  type: "Dropout"
  bottom: "cluster"
  top: "cluster"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "cluster"
  top: "cluster"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "cluster"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "ip2"
  top: "prob"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "prob"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0621 21:59:33.354787 18138 layer_factory.hpp:77] Creating layer mnist
I0621 21:59:33.354920 18138 net.cpp:91] Creating Layer mnist
I0621 21:59:33.354933 18138 net.cpp:399] mnist -> data
I0621 21:59:33.354943 18138 net.cpp:399] mnist -> label
I0621 21:59:33.355638 18147 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_test_lmdb
I0621 21:59:33.355761 18138 data_layer.cpp:41] output data size: 100,1,28,28
I0621 21:59:33.356736 18138 net.cpp:141] Setting up mnist
I0621 21:59:33.356751 18138 net.cpp:148] Top shape: 100 1 28 28 (78400)
I0621 21:59:33.356757 18138 net.cpp:148] Top shape: 100 (100)
I0621 21:59:33.356761 18138 net.cpp:156] Memory required for data: 314000
I0621 21:59:33.356766 18138 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0621 21:59:33.356776 18138 net.cpp:91] Creating Layer label_mnist_1_split
I0621 21:59:33.356782 18138 net.cpp:425] label_mnist_1_split <- label
I0621 21:59:33.356792 18138 net.cpp:399] label_mnist_1_split -> label_mnist_1_split_0
I0621 21:59:33.356806 18138 net.cpp:399] label_mnist_1_split -> label_mnist_1_split_1
I0621 21:59:33.356873 18138 net.cpp:141] Setting up label_mnist_1_split
I0621 21:59:33.356884 18138 net.cpp:148] Top shape: 100 (100)
I0621 21:59:33.356889 18138 net.cpp:148] Top shape: 100 (100)
I0621 21:59:33.356894 18138 net.cpp:156] Memory required for data: 314800
I0621 21:59:33.356905 18138 layer_factory.hpp:77] Creating layer conv1
I0621 21:59:33.356923 18138 net.cpp:91] Creating Layer conv1
I0621 21:59:33.356932 18138 net.cpp:425] conv1 <- data
I0621 21:59:33.356941 18138 net.cpp:399] conv1 -> conv1
I0621 21:59:33.358149 18138 net.cpp:141] Setting up conv1
I0621 21:59:33.358165 18138 net.cpp:148] Top shape: 100 20 24 24 (1152000)
I0621 21:59:33.358171 18138 net.cpp:156] Memory required for data: 4922800
I0621 21:59:33.358183 18138 layer_factory.hpp:77] Creating layer pool1
I0621 21:59:33.358198 18138 net.cpp:91] Creating Layer pool1
I0621 21:59:33.358211 18138 net.cpp:425] pool1 <- conv1
I0621 21:59:33.358225 18138 net.cpp:399] pool1 -> pool1
I0621 21:59:33.358289 18138 net.cpp:141] Setting up pool1
I0621 21:59:33.358301 18138 net.cpp:148] Top shape: 100 20 12 12 (288000)
I0621 21:59:33.358310 18138 net.cpp:156] Memory required for data: 6074800
I0621 21:59:33.358321 18138 layer_factory.hpp:77] Creating layer conv2
I0621 21:59:33.358342 18138 net.cpp:91] Creating Layer conv2
I0621 21:59:33.358355 18138 net.cpp:425] conv2 <- pool1
I0621 21:59:33.358382 18138 net.cpp:399] conv2 -> conv2
I0621 21:59:33.359650 18138 net.cpp:141] Setting up conv2
I0621 21:59:33.359666 18138 net.cpp:148] Top shape: 100 50 8 8 (320000)
I0621 21:59:33.359675 18138 net.cpp:156] Memory required for data: 7354800
I0621 21:59:33.359695 18138 layer_factory.hpp:77] Creating layer pool2
I0621 21:59:33.359711 18138 net.cpp:91] Creating Layer pool2
I0621 21:59:33.359737 18138 net.cpp:425] pool2 <- conv2
I0621 21:59:33.359757 18138 net.cpp:399] pool2 -> pool2
I0621 21:59:33.359822 18138 net.cpp:141] Setting up pool2
I0621 21:59:33.359835 18138 net.cpp:148] Top shape: 100 50 4 4 (80000)
I0621 21:59:33.359843 18138 net.cpp:156] Memory required for data: 7674800
I0621 21:59:33.359853 18138 layer_factory.hpp:77] Creating layer pool2_pool2_0_split
I0621 21:59:33.359874 18138 net.cpp:91] Creating Layer pool2_pool2_0_split
I0621 21:59:33.359885 18138 net.cpp:425] pool2_pool2_0_split <- pool2
I0621 21:59:33.359899 18138 net.cpp:399] pool2_pool2_0_split -> pool2_pool2_0_split_0
I0621 21:59:33.359922 18138 net.cpp:399] pool2_pool2_0_split -> pool2_pool2_0_split_1
I0621 21:59:33.359982 18138 net.cpp:141] Setting up pool2_pool2_0_split
I0621 21:59:33.359999 18138 net.cpp:148] Top shape: 100 50 4 4 (80000)
I0621 21:59:33.360008 18138 net.cpp:148] Top shape: 100 50 4 4 (80000)
I0621 21:59:33.360024 18138 net.cpp:156] Memory required for data: 8314800
I0621 21:59:33.360034 18138 layer_factory.hpp:77] Creating layer cluster_shortpath
I0621 21:59:33.360049 18138 net.cpp:91] Creating Layer cluster_shortpath
I0621 21:59:33.360066 18138 net.cpp:425] cluster_shortpath <- pool2_pool2_0_split_0
I0621 21:59:33.360085 18138 net.cpp:399] cluster_shortpath -> cluster_shortpath
I0621 21:59:33.361768 18138 net.cpp:141] Setting up cluster_shortpath
I0621 21:59:33.361783 18138 net.cpp:148] Top shape: 100 250 (25000)
I0621 21:59:33.361788 18138 net.cpp:156] Memory required for data: 8414800
I0621 21:59:33.361802 18138 layer_factory.hpp:77] Creating layer cluster_cluster
I0621 21:59:33.361819 18138 net.cpp:91] Creating Layer cluster_cluster
I0621 21:59:33.361829 18138 net.cpp:425] cluster_cluster <- pool2_pool2_0_split_1
I0621 21:59:33.361845 18138 net.cpp:399] cluster_cluster -> cluster_cluster
I0621 21:59:33.407218 18138 net.cpp:141] Setting up cluster_cluster
I0621 21:59:33.407253 18138 net.cpp:148] Top shape: 100 250 (25000)
I0621 21:59:33.407258 18138 net.cpp:156] Memory required for data: 8514800
I0621 21:59:33.407390 18138 layer_factory.hpp:77] Creating layer cluster
I0621 21:59:33.407412 18138 net.cpp:91] Creating Layer cluster
I0621 21:59:33.407423 18138 net.cpp:425] cluster <- cluster_cluster
I0621 21:59:33.407430 18138 net.cpp:425] cluster <- cluster_shortpath
I0621 21:59:33.407438 18138 net.cpp:399] cluster -> cluster
I0621 21:59:33.407480 18138 net.cpp:141] Setting up cluster
I0621 21:59:33.407495 18138 net.cpp:148] Top shape: 100 500 (50000)
I0621 21:59:33.407501 18138 net.cpp:156] Memory required for data: 8714800
I0621 21:59:33.407505 18138 layer_factory.hpp:77] Creating layer dropout
I0621 21:59:33.407513 18138 net.cpp:91] Creating Layer dropout
I0621 21:59:33.407517 18138 net.cpp:425] dropout <- cluster
I0621 21:59:33.407524 18138 net.cpp:386] dropout -> cluster (in-place)
I0621 21:59:33.407560 18138 net.cpp:141] Setting up dropout
I0621 21:59:33.407578 18138 net.cpp:148] Top shape: 100 500 (50000)
I0621 21:59:33.407588 18138 net.cpp:156] Memory required for data: 8914800
I0621 21:59:33.407595 18138 layer_factory.hpp:77] Creating layer relu1
I0621 21:59:33.407609 18138 net.cpp:91] Creating Layer relu1
I0621 21:59:33.407619 18138 net.cpp:425] relu1 <- cluster
I0621 21:59:33.407629 18138 net.cpp:386] relu1 -> cluster (in-place)
I0621 21:59:33.407860 18138 net.cpp:141] Setting up relu1
I0621 21:59:33.407873 18138 net.cpp:148] Top shape: 100 500 (50000)
I0621 21:59:33.407877 18138 net.cpp:156] Memory required for data: 9114800
I0621 21:59:33.407882 18138 layer_factory.hpp:77] Creating layer ip2
I0621 21:59:33.407892 18138 net.cpp:91] Creating Layer ip2
I0621 21:59:33.407896 18138 net.cpp:425] ip2 <- cluster
I0621 21:59:33.407904 18138 net.cpp:399] ip2 -> ip2
I0621 21:59:33.408080 18138 net.cpp:141] Setting up ip2
I0621 21:59:33.408092 18138 net.cpp:148] Top shape: 100 10 (1000)
I0621 21:59:33.408097 18138 net.cpp:156] Memory required for data: 9118800
I0621 21:59:33.408103 18138 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0621 21:59:33.408110 18138 net.cpp:91] Creating Layer ip2_ip2_0_split
I0621 21:59:33.408114 18138 net.cpp:425] ip2_ip2_0_split <- ip2
I0621 21:59:33.408120 18138 net.cpp:399] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0621 21:59:33.408129 18138 net.cpp:399] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0621 21:59:33.408190 18138 net.cpp:141] Setting up ip2_ip2_0_split
I0621 21:59:33.408200 18138 net.cpp:148] Top shape: 100 10 (1000)
I0621 21:59:33.408206 18138 net.cpp:148] Top shape: 100 10 (1000)
I0621 21:59:33.408210 18138 net.cpp:156] Memory required for data: 9126800
I0621 21:59:33.408215 18138 layer_factory.hpp:77] Creating layer prob
I0621 21:59:33.408224 18138 net.cpp:91] Creating Layer prob
I0621 21:59:33.408229 18138 net.cpp:425] prob <- ip2_ip2_0_split_0
I0621 21:59:33.408236 18138 net.cpp:399] prob -> prob
I0621 21:59:33.408622 18138 net.cpp:141] Setting up prob
I0621 21:59:33.408637 18138 net.cpp:148] Top shape: 100 10 (1000)
I0621 21:59:33.408641 18138 net.cpp:156] Memory required for data: 9130800
I0621 21:59:33.408645 18138 layer_factory.hpp:77] Creating layer accuracy
I0621 21:59:33.408654 18138 net.cpp:91] Creating Layer accuracy
I0621 21:59:33.408659 18138 net.cpp:425] accuracy <- prob
I0621 21:59:33.408665 18138 net.cpp:425] accuracy <- label_mnist_1_split_0
I0621 21:59:33.408670 18138 net.cpp:399] accuracy -> accuracy
I0621 21:59:33.408680 18138 net.cpp:141] Setting up accuracy
I0621 21:59:33.408686 18138 net.cpp:148] Top shape: (1)
I0621 21:59:33.408694 18138 net.cpp:156] Memory required for data: 9130804
I0621 21:59:33.408700 18138 layer_factory.hpp:77] Creating layer loss
I0621 21:59:33.408716 18138 net.cpp:91] Creating Layer loss
I0621 21:59:33.408727 18138 net.cpp:425] loss <- ip2_ip2_0_split_1
I0621 21:59:33.408737 18138 net.cpp:425] loss <- label_mnist_1_split_1
I0621 21:59:33.408746 18138 net.cpp:399] loss -> loss
I0621 21:59:33.408761 18138 layer_factory.hpp:77] Creating layer loss
I0621 21:59:33.409273 18138 net.cpp:141] Setting up loss
I0621 21:59:33.409286 18138 net.cpp:148] Top shape: (1)
I0621 21:59:33.409289 18138 net.cpp:151]     with loss weight 1
I0621 21:59:33.409302 18138 net.cpp:156] Memory required for data: 9130808
I0621 21:59:33.409307 18138 net.cpp:217] loss needs backward computation.
I0621 21:59:33.409312 18138 net.cpp:219] accuracy does not need backward computation.
I0621 21:59:33.409317 18138 net.cpp:219] prob does not need backward computation.
I0621 21:59:33.409322 18138 net.cpp:217] ip2_ip2_0_split needs backward computation.
I0621 21:59:33.409325 18138 net.cpp:217] ip2 needs backward computation.
I0621 21:59:33.409329 18138 net.cpp:217] relu1 needs backward computation.
I0621 21:59:33.409332 18138 net.cpp:217] dropout needs backward computation.
I0621 21:59:33.409337 18138 net.cpp:217] cluster needs backward computation.
I0621 21:59:33.409342 18138 net.cpp:217] cluster_cluster needs backward computation.
I0621 21:59:33.409349 18138 net.cpp:217] cluster_shortpath needs backward computation.
I0621 21:59:33.409356 18138 net.cpp:217] pool2_pool2_0_split needs backward computation.
I0621 21:59:33.409364 18138 net.cpp:217] pool2 needs backward computation.
I0621 21:59:33.409373 18138 net.cpp:217] conv2 needs backward computation.
I0621 21:59:33.409380 18138 net.cpp:217] pool1 needs backward computation.
I0621 21:59:33.409387 18138 net.cpp:217] conv1 needs backward computation.
I0621 21:59:33.409396 18138 net.cpp:219] label_mnist_1_split does not need backward computation.
I0621 21:59:33.409407 18138 net.cpp:219] mnist does not need backward computation.
I0621 21:59:33.409415 18138 net.cpp:261] This network produces output accuracy
I0621 21:59:33.409423 18138 net.cpp:261] This network produces output loss
I0621 21:59:33.409446 18138 net.cpp:274] Network initialization done.
I0621 21:59:33.409530 18138 solver.cpp:60] Solver scaffolding done.
I0621 21:59:33.414887 18138 caffe.cpp:219] Starting Optimization
I0621 21:59:33.414899 18138 solver.cpp:279] Solving LeNet
I0621 21:59:33.414903 18138 solver.cpp:280] Learning Rate Policy: fixed
I0621 21:59:33.419853 18138 solver.cpp:337] Iteration 0, Testing net (#0)
I0621 21:59:35.140804 18138 solver.cpp:404]     Test net output #0: accuracy = 0.0786
I0621 21:59:35.140843 18138 solver.cpp:404]     Test net output #1: loss = 2.29981 (* 1 = 2.29981 loss)
I0621 21:59:35.268687 18138 solver.cpp:228] Iteration 0, loss = 2.35575
I0621 21:59:35.268730 18138 solver.cpp:244]     Train net output #0: loss = 2.35575 (* 1 = 2.35575 loss)
I0621 21:59:35.268739 18138 sgd_solver.cpp:106] Iteration 0, lr = 0.001
E0621 22:00:17.476394 18138 clustering_layer.cpp:286] K 20 (2183 727 706 938 612 1286 1005 564 946 746 1272 999 1363 1325 1366 891 553 799 708 1011 )
E0621 22:00:17.476425 18138 clustering_layer.cpp:291] Layer cluster_cluster K Means split into 1 x 20 nodes, error: 351.411 error(ref): 0.724245
I0621 22:00:20.222158 18138 solver.cpp:228] Iteration 100, loss = 0.241724
I0621 22:00:20.222198 18138 solver.cpp:244]     Train net output #0: loss = 0.241724 (* 1 = 0.241724 loss)
I0621 22:00:20.222206 18138 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0621 22:00:32.107918 18138 solver.cpp:228] Iteration 200, loss = 0.129206
I0621 22:00:32.107955 18138 solver.cpp:244]     Train net output #0: loss = 0.129206 (* 1 = 0.129206 loss)
I0621 22:00:32.107964 18138 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0621 22:00:43.965224 18138 solver.cpp:228] Iteration 300, loss = 0.11543
I0621 22:00:43.965265 18138 solver.cpp:244]     Train net output #0: loss = 0.11543 (* 1 = 0.11543 loss)
I0621 22:00:43.965272 18138 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0621 22:00:55.837875 18138 solver.cpp:228] Iteration 400, loss = 0.14431
I0621 22:00:55.837914 18138 solver.cpp:244]     Train net output #0: loss = 0.14431 (* 1 = 0.14431 loss)
I0621 22:00:55.837923 18138 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0621 22:01:07.607950 18138 solver.cpp:337] Iteration 500, Testing net (#0)
I0621 22:01:09.346139 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9826
I0621 22:01:09.346186 18138 solver.cpp:404]     Test net output #1: loss = 0.0525141 (* 1 = 0.0525141 loss)
I0621 22:01:09.464215 18138 solver.cpp:228] Iteration 500, loss = 0.102678
I0621 22:01:09.464262 18138 solver.cpp:244]     Train net output #0: loss = 0.102678 (* 1 = 0.102678 loss)
I0621 22:01:09.464270 18138 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0621 22:01:21.361204 18138 solver.cpp:228] Iteration 600, loss = 0.0466656
I0621 22:01:21.361244 18138 solver.cpp:244]     Train net output #0: loss = 0.0466657 (* 1 = 0.0466657 loss)
I0621 22:01:21.361253 18138 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0621 22:01:33.212980 18138 solver.cpp:228] Iteration 700, loss = 0.0532541
I0621 22:01:33.213021 18138 solver.cpp:244]     Train net output #0: loss = 0.0532541 (* 1 = 0.0532541 loss)
I0621 22:01:33.213029 18138 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0621 22:01:45.125655 18138 solver.cpp:228] Iteration 800, loss = 0.0488007
I0621 22:01:45.125694 18138 solver.cpp:244]     Train net output #0: loss = 0.0488008 (* 1 = 0.0488008 loss)
I0621 22:01:45.125701 18138 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0621 22:01:57.027938 18138 solver.cpp:228] Iteration 900, loss = 0.054042
I0621 22:01:57.027977 18138 solver.cpp:244]     Train net output #0: loss = 0.0540421 (* 1 = 0.0540421 loss)
I0621 22:01:57.027987 18138 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0621 22:02:08.764925 18138 solver.cpp:337] Iteration 1000, Testing net (#0)
I0621 22:02:10.499020 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9886
I0621 22:02:10.499058 18138 solver.cpp:404]     Test net output #1: loss = 0.0364808 (* 1 = 0.0364808 loss)
I0621 22:02:10.616541 18138 solver.cpp:228] Iteration 1000, loss = 0.0453434
I0621 22:02:10.616586 18138 solver.cpp:244]     Train net output #0: loss = 0.0453434 (* 1 = 0.0453434 loss)
I0621 22:02:10.616595 18138 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0621 22:02:22.529568 18138 solver.cpp:228] Iteration 1100, loss = 0.0244534
I0621 22:02:22.529608 18138 solver.cpp:244]     Train net output #0: loss = 0.0244534 (* 1 = 0.0244534 loss)
I0621 22:02:22.529616 18138 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0621 22:02:34.437999 18138 solver.cpp:228] Iteration 1200, loss = 0.0717799
I0621 22:02:34.438038 18138 solver.cpp:244]     Train net output #0: loss = 0.0717799 (* 1 = 0.0717799 loss)
I0621 22:02:34.438046 18138 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0621 22:02:46.358207 18138 solver.cpp:228] Iteration 1300, loss = 0.0259792
I0621 22:02:46.358247 18138 solver.cpp:244]     Train net output #0: loss = 0.0259793 (* 1 = 0.0259793 loss)
I0621 22:02:46.358255 18138 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0621 22:02:58.280582 18138 solver.cpp:228] Iteration 1400, loss = 0.00950641
I0621 22:02:58.280623 18138 solver.cpp:244]     Train net output #0: loss = 0.00950647 (* 1 = 0.00950647 loss)
I0621 22:02:58.280632 18138 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0621 22:03:09.949059 18138 solver.cpp:337] Iteration 1500, Testing net (#0)
I0621 22:03:11.680050 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9898
I0621 22:03:11.680088 18138 solver.cpp:404]     Test net output #1: loss = 0.028261 (* 1 = 0.028261 loss)
I0621 22:03:11.795861 18138 solver.cpp:228] Iteration 1500, loss = 0.0333384
I0621 22:03:11.795907 18138 solver.cpp:244]     Train net output #0: loss = 0.0333385 (* 1 = 0.0333385 loss)
I0621 22:03:11.795915 18138 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0621 22:03:23.674309 18138 solver.cpp:228] Iteration 1600, loss = 0.0286843
I0621 22:03:23.674346 18138 solver.cpp:244]     Train net output #0: loss = 0.0286844 (* 1 = 0.0286844 loss)
I0621 22:03:23.674355 18138 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0621 22:03:35.510253 18138 solver.cpp:228] Iteration 1700, loss = 0.0472646
I0621 22:03:35.510293 18138 solver.cpp:244]     Train net output #0: loss = 0.0472647 (* 1 = 0.0472647 loss)
I0621 22:03:35.510301 18138 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0621 22:03:47.420337 18138 solver.cpp:228] Iteration 1800, loss = 0.022265
I0621 22:03:47.420375 18138 solver.cpp:244]     Train net output #0: loss = 0.0222651 (* 1 = 0.0222651 loss)
I0621 22:03:47.420383 18138 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0621 22:03:59.332178 18138 solver.cpp:228] Iteration 1900, loss = 0.0170129
I0621 22:03:59.332216 18138 solver.cpp:244]     Train net output #0: loss = 0.017013 (* 1 = 0.017013 loss)
I0621 22:03:59.332226 18138 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0621 22:04:11.133841 18138 solver.cpp:337] Iteration 2000, Testing net (#0)
I0621 22:04:12.866029 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9868
I0621 22:04:12.866068 18138 solver.cpp:404]     Test net output #1: loss = 0.0412642 (* 1 = 0.0412642 loss)
I0621 22:04:12.982539 18138 solver.cpp:228] Iteration 2000, loss = 0.0370609
I0621 22:04:12.982584 18138 solver.cpp:244]     Train net output #0: loss = 0.0370609 (* 1 = 0.0370609 loss)
I0621 22:04:12.982594 18138 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0621 22:04:24.887116 18138 solver.cpp:228] Iteration 2100, loss = 0.023998
I0621 22:04:24.887154 18138 solver.cpp:244]     Train net output #0: loss = 0.023998 (* 1 = 0.023998 loss)
I0621 22:04:24.887163 18138 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0621 22:04:36.764879 18138 solver.cpp:228] Iteration 2200, loss = 0.00247683
I0621 22:04:36.764919 18138 solver.cpp:244]     Train net output #0: loss = 0.00247689 (* 1 = 0.00247689 loss)
I0621 22:04:36.764927 18138 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0621 22:04:48.564123 18138 solver.cpp:228] Iteration 2300, loss = 0.0531116
I0621 22:04:48.564163 18138 solver.cpp:244]     Train net output #0: loss = 0.0531116 (* 1 = 0.0531116 loss)
I0621 22:04:48.564172 18138 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0621 22:05:00.472470 18138 solver.cpp:228] Iteration 2400, loss = 0.0166546
I0621 22:05:00.472509 18138 solver.cpp:244]     Train net output #0: loss = 0.0166546 (* 1 = 0.0166546 loss)
I0621 22:05:00.472517 18138 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0621 22:05:12.233577 18138 solver.cpp:337] Iteration 2500, Testing net (#0)
I0621 22:05:13.963192 18138 solver.cpp:404]     Test net output #0: accuracy = 0.991
I0621 22:05:13.963229 18138 solver.cpp:404]     Test net output #1: loss = 0.02791 (* 1 = 0.02791 loss)
I0621 22:05:14.079931 18138 solver.cpp:228] Iteration 2500, loss = 0.0320899
I0621 22:05:14.079977 18138 solver.cpp:244]     Train net output #0: loss = 0.03209 (* 1 = 0.03209 loss)
I0621 22:05:14.079984 18138 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0621 22:05:25.981878 18138 solver.cpp:228] Iteration 2600, loss = 0.052773
I0621 22:05:25.981916 18138 solver.cpp:244]     Train net output #0: loss = 0.0527731 (* 1 = 0.0527731 loss)
I0621 22:05:25.981925 18138 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0621 22:05:37.879981 18138 solver.cpp:228] Iteration 2700, loss = 0.01492
I0621 22:05:37.880020 18138 solver.cpp:244]     Train net output #0: loss = 0.0149201 (* 1 = 0.0149201 loss)
I0621 22:05:37.880029 18138 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0621 22:05:49.794152 18138 solver.cpp:228] Iteration 2800, loss = 0.012378
I0621 22:05:49.794193 18138 solver.cpp:244]     Train net output #0: loss = 0.012378 (* 1 = 0.012378 loss)
I0621 22:05:49.794200 18138 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0621 22:06:01.692970 18138 solver.cpp:228] Iteration 2900, loss = 0.0279482
I0621 22:06:01.693011 18138 solver.cpp:244]     Train net output #0: loss = 0.0279483 (* 1 = 0.0279483 loss)
I0621 22:06:01.693018 18138 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0621 22:06:13.422767 18138 solver.cpp:337] Iteration 3000, Testing net (#0)
I0621 22:06:15.124032 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9908
I0621 22:06:15.124071 18138 solver.cpp:404]     Test net output #1: loss = 0.0317832 (* 1 = 0.0317832 loss)
I0621 22:06:15.238370 18138 solver.cpp:228] Iteration 3000, loss = 0.00925704
I0621 22:06:15.238415 18138 solver.cpp:244]     Train net output #0: loss = 0.00925709 (* 1 = 0.00925709 loss)
I0621 22:06:15.238425 18138 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0621 22:06:27.056133 18138 solver.cpp:228] Iteration 3100, loss = 0.0238277
I0621 22:06:27.056171 18138 solver.cpp:244]     Train net output #0: loss = 0.0238277 (* 1 = 0.0238277 loss)
I0621 22:06:27.056180 18138 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0621 22:06:38.851747 18138 solver.cpp:228] Iteration 3200, loss = 0.0191205
I0621 22:06:38.851788 18138 solver.cpp:244]     Train net output #0: loss = 0.0191205 (* 1 = 0.0191205 loss)
I0621 22:06:38.851795 18138 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0621 22:06:50.649752 18138 solver.cpp:228] Iteration 3300, loss = 0.0226724
I0621 22:06:50.649793 18138 solver.cpp:244]     Train net output #0: loss = 0.0226724 (* 1 = 0.0226724 loss)
I0621 22:06:50.649801 18138 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0621 22:07:02.405279 18138 solver.cpp:228] Iteration 3400, loss = 0.00642974
I0621 22:07:02.405318 18138 solver.cpp:244]     Train net output #0: loss = 0.00642981 (* 1 = 0.00642981 loss)
I0621 22:07:02.405326 18138 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0621 22:07:14.007238 18138 solver.cpp:337] Iteration 3500, Testing net (#0)
I0621 22:07:15.692832 18138 solver.cpp:404]     Test net output #0: accuracy = 0.991
I0621 22:07:15.692872 18138 solver.cpp:404]     Test net output #1: loss = 0.033478 (* 1 = 0.033478 loss)
I0621 22:07:15.806534 18138 solver.cpp:228] Iteration 3500, loss = 0.0108576
I0621 22:07:15.806579 18138 solver.cpp:244]     Train net output #0: loss = 0.0108577 (* 1 = 0.0108577 loss)
I0621 22:07:15.806587 18138 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0621 22:07:27.418432 18138 solver.cpp:228] Iteration 3600, loss = 0.0025003
I0621 22:07:27.418470 18138 solver.cpp:244]     Train net output #0: loss = 0.00250035 (* 1 = 0.00250035 loss)
I0621 22:07:27.418478 18138 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0621 22:07:39.137737 18138 solver.cpp:228] Iteration 3700, loss = 0.0397859
I0621 22:07:39.137776 18138 solver.cpp:244]     Train net output #0: loss = 0.0397859 (* 1 = 0.0397859 loss)
I0621 22:07:39.137784 18138 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0621 22:07:50.895066 18138 solver.cpp:228] Iteration 3800, loss = 0.0409551
I0621 22:07:50.895105 18138 solver.cpp:244]     Train net output #0: loss = 0.0409551 (* 1 = 0.0409551 loss)
I0621 22:07:50.895113 18138 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0621 22:08:02.650216 18138 solver.cpp:228] Iteration 3900, loss = 0.0416907
I0621 22:08:02.650254 18138 solver.cpp:244]     Train net output #0: loss = 0.0416908 (* 1 = 0.0416908 loss)
I0621 22:08:02.650262 18138 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0621 22:08:14.291990 18138 solver.cpp:337] Iteration 4000, Testing net (#0)
I0621 22:08:15.978334 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9914
I0621 22:08:15.978374 18138 solver.cpp:404]     Test net output #1: loss = 0.0306214 (* 1 = 0.0306214 loss)
I0621 22:08:16.091487 18138 solver.cpp:228] Iteration 4000, loss = 0.00504355
I0621 22:08:16.091534 18138 solver.cpp:244]     Train net output #0: loss = 0.00504361 (* 1 = 0.00504361 loss)
I0621 22:08:16.091543 18138 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0621 22:08:27.806624 18138 solver.cpp:228] Iteration 4100, loss = 0.0303045
I0621 22:08:27.806664 18138 solver.cpp:244]     Train net output #0: loss = 0.0303045 (* 1 = 0.0303045 loss)
I0621 22:08:27.806673 18138 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0621 22:08:39.461524 18138 solver.cpp:228] Iteration 4200, loss = 0.0258264
I0621 22:08:39.461561 18138 solver.cpp:244]     Train net output #0: loss = 0.0258265 (* 1 = 0.0258265 loss)
I0621 22:08:39.461570 18138 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0621 22:08:51.158308 18138 solver.cpp:228] Iteration 4300, loss = 0.00697929
I0621 22:08:51.158349 18138 solver.cpp:244]     Train net output #0: loss = 0.00697933 (* 1 = 0.00697933 loss)
I0621 22:08:51.158356 18138 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0621 22:09:02.797060 18138 solver.cpp:228] Iteration 4400, loss = 0.00325529
I0621 22:09:02.797098 18138 solver.cpp:244]     Train net output #0: loss = 0.00325532 (* 1 = 0.00325532 loss)
I0621 22:09:02.797106 18138 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0621 22:09:14.427078 18138 solver.cpp:337] Iteration 4500, Testing net (#0)
I0621 22:09:16.112920 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9903
I0621 22:09:16.112958 18138 solver.cpp:404]     Test net output #1: loss = 0.036638 (* 1 = 0.036638 loss)
I0621 22:09:16.226254 18138 solver.cpp:228] Iteration 4500, loss = 0.00742469
I0621 22:09:16.226300 18138 solver.cpp:244]     Train net output #0: loss = 0.00742473 (* 1 = 0.00742473 loss)
I0621 22:09:16.226310 18138 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0621 22:09:27.954668 18138 solver.cpp:228] Iteration 4600, loss = 0.0168501
I0621 22:09:27.954707 18138 solver.cpp:244]     Train net output #0: loss = 0.0168501 (* 1 = 0.0168501 loss)
I0621 22:09:27.954716 18138 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0621 22:09:39.705843 18138 solver.cpp:228] Iteration 4700, loss = 0.00120287
I0621 22:09:39.705883 18138 solver.cpp:244]     Train net output #0: loss = 0.00120291 (* 1 = 0.00120291 loss)
I0621 22:09:39.705893 18138 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0621 22:09:51.464942 18138 solver.cpp:228] Iteration 4800, loss = 0.00782329
I0621 22:09:51.464980 18138 solver.cpp:244]     Train net output #0: loss = 0.00782333 (* 1 = 0.00782333 loss)
I0621 22:09:51.464988 18138 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0621 22:10:03.184268 18138 solver.cpp:228] Iteration 4900, loss = 0.0131189
I0621 22:10:03.184309 18138 solver.cpp:244]     Train net output #0: loss = 0.0131189 (* 1 = 0.0131189 loss)
I0621 22:10:03.184321 18138 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0621 22:10:14.789300 18138 solver.cpp:454] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I0621 22:10:14.910537 18138 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I0621 22:10:15.077064 18138 solver.cpp:337] Iteration 5000, Testing net (#0)
I0621 22:10:16.882921 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9904
I0621 22:10:16.882961 18138 solver.cpp:404]     Test net output #1: loss = 0.0425116 (* 1 = 0.0425116 loss)
I0621 22:10:17.000636 18138 solver.cpp:228] Iteration 5000, loss = 0.0211386
I0621 22:10:17.000681 18138 solver.cpp:244]     Train net output #0: loss = 0.0211387 (* 1 = 0.0211387 loss)
I0621 22:10:17.000690 18138 sgd_solver.cpp:106] Iteration 5000, lr = 0.001
I0621 22:10:29.111353 18138 solver.cpp:228] Iteration 5100, loss = 0.0116931
I0621 22:10:29.111393 18138 solver.cpp:244]     Train net output #0: loss = 0.0116931 (* 1 = 0.0116931 loss)
I0621 22:10:29.111402 18138 sgd_solver.cpp:106] Iteration 5100, lr = 0.001
I0621 22:10:41.215431 18138 solver.cpp:228] Iteration 5200, loss = 0.0261431
I0621 22:10:41.215471 18138 solver.cpp:244]     Train net output #0: loss = 0.0261431 (* 1 = 0.0261431 loss)
I0621 22:10:41.215479 18138 sgd_solver.cpp:106] Iteration 5200, lr = 0.001
I0621 22:10:53.329814 18138 solver.cpp:228] Iteration 5300, loss = 0.00932681
I0621 22:10:53.329856 18138 solver.cpp:244]     Train net output #0: loss = 0.00932684 (* 1 = 0.00932684 loss)
I0621 22:10:53.329865 18138 sgd_solver.cpp:106] Iteration 5300, lr = 0.001
I0621 22:11:05.417614 18138 solver.cpp:228] Iteration 5400, loss = 0.0172368
I0621 22:11:05.417654 18138 solver.cpp:244]     Train net output #0: loss = 0.0172368 (* 1 = 0.0172368 loss)
I0621 22:11:05.417662 18138 sgd_solver.cpp:106] Iteration 5400, lr = 0.001
I0621 22:11:17.386091 18138 solver.cpp:337] Iteration 5500, Testing net (#0)
I0621 22:11:19.160754 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9907
I0621 22:11:19.160792 18138 solver.cpp:404]     Test net output #1: loss = 0.0372509 (* 1 = 0.0372509 loss)
I0621 22:11:19.278511 18138 solver.cpp:228] Iteration 5500, loss = 0.00736837
I0621 22:11:19.278555 18138 solver.cpp:244]     Train net output #0: loss = 0.0073684 (* 1 = 0.0073684 loss)
I0621 22:11:19.278564 18138 sgd_solver.cpp:106] Iteration 5500, lr = 0.001
I0621 22:11:31.301650 18138 solver.cpp:228] Iteration 5600, loss = 0.00649303
I0621 22:11:31.301692 18138 solver.cpp:244]     Train net output #0: loss = 0.00649305 (* 1 = 0.00649305 loss)
I0621 22:11:31.301700 18138 sgd_solver.cpp:106] Iteration 5600, lr = 0.001
I0621 22:11:43.298646 18138 solver.cpp:228] Iteration 5700, loss = 0.00360977
I0621 22:11:43.298686 18138 solver.cpp:244]     Train net output #0: loss = 0.00360979 (* 1 = 0.00360979 loss)
I0621 22:11:43.298694 18138 sgd_solver.cpp:106] Iteration 5700, lr = 0.001
I0621 22:11:55.332384 18138 solver.cpp:228] Iteration 5800, loss = 0.00534444
I0621 22:11:55.332427 18138 solver.cpp:244]     Train net output #0: loss = 0.00534447 (* 1 = 0.00534447 loss)
I0621 22:11:55.332435 18138 sgd_solver.cpp:106] Iteration 5800, lr = 0.001
I0621 22:12:07.605819 18138 solver.cpp:228] Iteration 5900, loss = 0.000222577
I0621 22:12:07.605859 18138 solver.cpp:244]     Train net output #0: loss = 0.00022261 (* 1 = 0.00022261 loss)
I0621 22:12:07.605866 18138 sgd_solver.cpp:106] Iteration 5900, lr = 0.001
I0621 22:12:19.573142 18138 solver.cpp:337] Iteration 6000, Testing net (#0)
I0621 22:12:21.347429 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9892
I0621 22:12:21.347467 18138 solver.cpp:404]     Test net output #1: loss = 0.0454516 (* 1 = 0.0454516 loss)
I0621 22:12:21.464275 18138 solver.cpp:228] Iteration 6000, loss = 0.00946588
I0621 22:12:21.464323 18138 solver.cpp:244]     Train net output #0: loss = 0.00946592 (* 1 = 0.00946592 loss)
I0621 22:12:21.464332 18138 sgd_solver.cpp:106] Iteration 6000, lr = 0.001
I0621 22:12:33.558768 18138 solver.cpp:228] Iteration 6100, loss = 0.0083948
I0621 22:12:33.558809 18138 solver.cpp:244]     Train net output #0: loss = 0.00839484 (* 1 = 0.00839484 loss)
I0621 22:12:33.558817 18138 sgd_solver.cpp:106] Iteration 6100, lr = 0.001
I0621 22:12:45.654144 18138 solver.cpp:228] Iteration 6200, loss = 0.0179207
I0621 22:12:45.654184 18138 solver.cpp:244]     Train net output #0: loss = 0.0179207 (* 1 = 0.0179207 loss)
I0621 22:12:45.654192 18138 sgd_solver.cpp:106] Iteration 6200, lr = 0.001
I0621 22:12:57.744002 18138 solver.cpp:228] Iteration 6300, loss = 0.0298865
I0621 22:12:57.744041 18138 solver.cpp:244]     Train net output #0: loss = 0.0298866 (* 1 = 0.0298866 loss)
I0621 22:12:57.744050 18138 sgd_solver.cpp:106] Iteration 6300, lr = 0.001
I0621 22:13:09.818253 18138 solver.cpp:228] Iteration 6400, loss = 0.0099401
I0621 22:13:09.818294 18138 solver.cpp:244]     Train net output #0: loss = 0.00994016 (* 1 = 0.00994016 loss)
I0621 22:13:09.818302 18138 sgd_solver.cpp:106] Iteration 6400, lr = 0.001
I0621 22:13:21.759747 18138 solver.cpp:337] Iteration 6500, Testing net (#0)
I0621 22:13:23.535568 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9918
I0621 22:13:23.535606 18138 solver.cpp:404]     Test net output #1: loss = 0.0390001 (* 1 = 0.0390001 loss)
I0621 22:13:23.652601 18138 solver.cpp:228] Iteration 6500, loss = 0.0264432
I0621 22:13:23.652645 18138 solver.cpp:244]     Train net output #0: loss = 0.0264433 (* 1 = 0.0264433 loss)
I0621 22:13:23.652654 18138 sgd_solver.cpp:106] Iteration 6500, lr = 0.001
I0621 22:13:35.752367 18138 solver.cpp:228] Iteration 6600, loss = 0.0103341
I0621 22:13:35.752406 18138 solver.cpp:244]     Train net output #0: loss = 0.0103342 (* 1 = 0.0103342 loss)
I0621 22:13:35.752414 18138 sgd_solver.cpp:106] Iteration 6600, lr = 0.001
I0621 22:13:47.852195 18138 solver.cpp:228] Iteration 6700, loss = 0.00437128
I0621 22:13:47.852234 18138 solver.cpp:244]     Train net output #0: loss = 0.00437133 (* 1 = 0.00437133 loss)
I0621 22:13:47.852243 18138 sgd_solver.cpp:106] Iteration 6700, lr = 0.001
I0621 22:14:00.104264 18138 solver.cpp:228] Iteration 6800, loss = 0.038599
I0621 22:14:00.104305 18138 solver.cpp:244]     Train net output #0: loss = 0.038599 (* 1 = 0.038599 loss)
I0621 22:14:00.104312 18138 sgd_solver.cpp:106] Iteration 6800, lr = 0.001
I0621 22:14:12.207628 18138 solver.cpp:228] Iteration 6900, loss = 0.0263809
I0621 22:14:12.207667 18138 solver.cpp:244]     Train net output #0: loss = 0.0263809 (* 1 = 0.0263809 loss)
I0621 22:14:12.207675 18138 sgd_solver.cpp:106] Iteration 6900, lr = 0.001
I0621 22:14:24.194689 18138 solver.cpp:337] Iteration 7000, Testing net (#0)
I0621 22:14:25.970873 18138 solver.cpp:404]     Test net output #0: accuracy = 0.992
I0621 22:14:25.970911 18138 solver.cpp:404]     Test net output #1: loss = 0.0419206 (* 1 = 0.0419206 loss)
I0621 22:14:26.087965 18138 solver.cpp:228] Iteration 7000, loss = 0.00618617
I0621 22:14:26.088011 18138 solver.cpp:244]     Train net output #0: loss = 0.00618619 (* 1 = 0.00618619 loss)
I0621 22:14:26.088021 18138 sgd_solver.cpp:106] Iteration 7000, lr = 0.001
I0621 22:14:38.187214 18138 solver.cpp:228] Iteration 7100, loss = 0.0269038
I0621 22:14:38.187254 18138 solver.cpp:244]     Train net output #0: loss = 0.0269038 (* 1 = 0.0269038 loss)
I0621 22:14:38.187263 18138 sgd_solver.cpp:106] Iteration 7100, lr = 0.001
I0621 22:14:50.281869 18138 solver.cpp:228] Iteration 7200, loss = 0.0268231
I0621 22:14:50.281913 18138 solver.cpp:244]     Train net output #0: loss = 0.0268231 (* 1 = 0.0268231 loss)
I0621 22:14:50.281920 18138 sgd_solver.cpp:106] Iteration 7200, lr = 0.001
I0621 22:15:02.383133 18138 solver.cpp:228] Iteration 7300, loss = 0.00969044
I0621 22:15:02.383174 18138 solver.cpp:244]     Train net output #0: loss = 0.00969047 (* 1 = 0.00969047 loss)
I0621 22:15:02.383183 18138 sgd_solver.cpp:106] Iteration 7300, lr = 0.001
I0621 22:15:14.446336 18138 solver.cpp:228] Iteration 7400, loss = 0.0295994
I0621 22:15:14.446375 18138 solver.cpp:244]     Train net output #0: loss = 0.0295994 (* 1 = 0.0295994 loss)
I0621 22:15:14.446383 18138 sgd_solver.cpp:106] Iteration 7400, lr = 0.001
I0621 22:15:26.407500 18138 solver.cpp:337] Iteration 7500, Testing net (#0)
I0621 22:15:28.184931 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9897
I0621 22:15:28.184969 18138 solver.cpp:404]     Test net output #1: loss = 0.0594869 (* 1 = 0.0594869 loss)
I0621 22:15:28.302858 18138 solver.cpp:228] Iteration 7500, loss = 0.000571348
I0621 22:15:28.302904 18138 solver.cpp:244]     Train net output #0: loss = 0.00057137 (* 1 = 0.00057137 loss)
I0621 22:15:28.302913 18138 sgd_solver.cpp:106] Iteration 7500, lr = 0.001
I0621 22:15:40.405310 18138 solver.cpp:228] Iteration 7600, loss = 0.00500725
I0621 22:15:40.405350 18138 solver.cpp:244]     Train net output #0: loss = 0.00500728 (* 1 = 0.00500728 loss)
I0621 22:15:40.405359 18138 sgd_solver.cpp:106] Iteration 7600, lr = 0.001
I0621 22:15:52.501047 18138 solver.cpp:228] Iteration 7700, loss = 0.0356536
I0621 22:15:52.501086 18138 solver.cpp:244]     Train net output #0: loss = 0.0356536 (* 1 = 0.0356536 loss)
I0621 22:15:52.501096 18138 sgd_solver.cpp:106] Iteration 7700, lr = 0.001
I0621 22:16:04.609105 18138 solver.cpp:228] Iteration 7800, loss = 0.00478426
I0621 22:16:04.609145 18138 solver.cpp:244]     Train net output #0: loss = 0.00478429 (* 1 = 0.00478429 loss)
I0621 22:16:04.609153 18138 sgd_solver.cpp:106] Iteration 7800, lr = 0.001
I0621 22:16:16.663759 18138 solver.cpp:228] Iteration 7900, loss = 0.0276006
I0621 22:16:16.663799 18138 solver.cpp:244]     Train net output #0: loss = 0.0276007 (* 1 = 0.0276007 loss)
I0621 22:16:16.663806 18138 sgd_solver.cpp:106] Iteration 7900, lr = 0.001
I0621 22:16:28.634387 18138 solver.cpp:337] Iteration 8000, Testing net (#0)
I0621 22:16:30.406749 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9903
I0621 22:16:30.406786 18138 solver.cpp:404]     Test net output #1: loss = 0.0538702 (* 1 = 0.0538702 loss)
I0621 22:16:30.523739 18138 solver.cpp:228] Iteration 8000, loss = 0.00266533
I0621 22:16:30.523782 18138 solver.cpp:244]     Train net output #0: loss = 0.00266537 (* 1 = 0.00266537 loss)
I0621 22:16:30.523792 18138 sgd_solver.cpp:106] Iteration 8000, lr = 0.001
I0621 22:16:42.614161 18138 solver.cpp:228] Iteration 8100, loss = 0.00152462
I0621 22:16:42.614202 18138 solver.cpp:244]     Train net output #0: loss = 0.00152466 (* 1 = 0.00152466 loss)
I0621 22:16:42.614210 18138 sgd_solver.cpp:106] Iteration 8100, lr = 0.001
I0621 22:16:54.885454 18138 solver.cpp:228] Iteration 8200, loss = 0.000807482
I0621 22:16:54.885495 18138 solver.cpp:244]     Train net output #0: loss = 0.000807532 (* 1 = 0.000807532 loss)
I0621 22:16:54.885504 18138 sgd_solver.cpp:106] Iteration 8200, lr = 0.001
I0621 22:17:07.159343 18138 solver.cpp:228] Iteration 8300, loss = 0.0075131
I0621 22:17:07.159381 18138 solver.cpp:244]     Train net output #0: loss = 0.00751316 (* 1 = 0.00751316 loss)
I0621 22:17:07.159389 18138 sgd_solver.cpp:106] Iteration 8300, lr = 0.001
I0621 22:17:19.227361 18138 solver.cpp:228] Iteration 8400, loss = 0.00453056
I0621 22:17:19.227404 18138 solver.cpp:244]     Train net output #0: loss = 0.00453063 (* 1 = 0.00453063 loss)
I0621 22:17:19.227412 18138 sgd_solver.cpp:106] Iteration 8400, lr = 0.001
I0621 22:17:31.196460 18138 solver.cpp:337] Iteration 8500, Testing net (#0)
I0621 22:17:32.968672 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9911
I0621 22:17:32.968710 18138 solver.cpp:404]     Test net output #1: loss = 0.0509453 (* 1 = 0.0509453 loss)
I0621 22:17:33.085800 18138 solver.cpp:228] Iteration 8500, loss = 0.00281631
I0621 22:17:33.085844 18138 solver.cpp:244]     Train net output #0: loss = 0.00281637 (* 1 = 0.00281637 loss)
I0621 22:17:33.085853 18138 sgd_solver.cpp:106] Iteration 8500, lr = 0.001
I0621 22:17:45.173039 18138 solver.cpp:228] Iteration 8600, loss = 0.0232208
I0621 22:17:45.173079 18138 solver.cpp:244]     Train net output #0: loss = 0.0232208 (* 1 = 0.0232208 loss)
I0621 22:17:45.173087 18138 sgd_solver.cpp:106] Iteration 8600, lr = 0.001
I0621 22:17:57.269232 18138 solver.cpp:228] Iteration 8700, loss = 0.040211
I0621 22:17:57.269273 18138 solver.cpp:244]     Train net output #0: loss = 0.040211 (* 1 = 0.040211 loss)
I0621 22:17:57.269281 18138 sgd_solver.cpp:106] Iteration 8700, lr = 0.001
I0621 22:18:09.334764 18138 solver.cpp:228] Iteration 8800, loss = 0.0018343
I0621 22:18:09.334806 18138 solver.cpp:244]     Train net output #0: loss = 0.00183435 (* 1 = 0.00183435 loss)
I0621 22:18:09.334815 18138 sgd_solver.cpp:106] Iteration 8800, lr = 0.001
I0621 22:18:21.424492 18138 solver.cpp:228] Iteration 8900, loss = 0.0104915
I0621 22:18:21.424532 18138 solver.cpp:244]     Train net output #0: loss = 0.0104916 (* 1 = 0.0104916 loss)
I0621 22:18:21.424540 18138 sgd_solver.cpp:106] Iteration 8900, lr = 0.001
I0621 22:18:33.342707 18138 solver.cpp:337] Iteration 9000, Testing net (#0)
I0621 22:18:35.116930 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9916
I0621 22:18:35.116968 18138 solver.cpp:404]     Test net output #1: loss = 0.0469588 (* 1 = 0.0469588 loss)
I0621 22:18:35.234169 18138 solver.cpp:228] Iteration 9000, loss = 0.00291412
I0621 22:18:35.234212 18138 solver.cpp:244]     Train net output #0: loss = 0.00291416 (* 1 = 0.00291416 loss)
I0621 22:18:35.234221 18138 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I0621 22:18:47.319175 18138 solver.cpp:228] Iteration 9100, loss = 0.00108665
I0621 22:18:47.319217 18138 solver.cpp:244]     Train net output #0: loss = 0.00108668 (* 1 = 0.00108668 loss)
I0621 22:18:47.319226 18138 sgd_solver.cpp:106] Iteration 9100, lr = 0.001
I0621 22:18:59.804944 18138 solver.cpp:228] Iteration 9200, loss = 0.0262935
I0621 22:18:59.804982 18138 solver.cpp:244]     Train net output #0: loss = 0.0262935 (* 1 = 0.0262935 loss)
I0621 22:18:59.804991 18138 sgd_solver.cpp:106] Iteration 9200, lr = 0.001
I0621 22:19:11.890795 18138 solver.cpp:228] Iteration 9300, loss = 0.00358275
I0621 22:19:11.890836 18138 solver.cpp:244]     Train net output #0: loss = 0.00358279 (* 1 = 0.00358279 loss)
I0621 22:19:11.890844 18138 sgd_solver.cpp:106] Iteration 9300, lr = 0.001
I0621 22:19:23.974033 18138 solver.cpp:228] Iteration 9400, loss = 0.0428805
I0621 22:19:23.974073 18138 solver.cpp:244]     Train net output #0: loss = 0.0428806 (* 1 = 0.0428806 loss)
I0621 22:19:23.974081 18138 sgd_solver.cpp:106] Iteration 9400, lr = 0.001
I0621 22:19:35.942947 18138 solver.cpp:337] Iteration 9500, Testing net (#0)
I0621 22:19:37.718188 18138 solver.cpp:404]     Test net output #0: accuracy = 0.99
I0621 22:19:37.718225 18138 solver.cpp:404]     Test net output #1: loss = 0.0599545 (* 1 = 0.0599545 loss)
I0621 22:19:37.835538 18138 solver.cpp:228] Iteration 9500, loss = 0.000258178
I0621 22:19:37.835585 18138 solver.cpp:244]     Train net output #0: loss = 0.000258234 (* 1 = 0.000258234 loss)
I0621 22:19:37.835594 18138 sgd_solver.cpp:106] Iteration 9500, lr = 0.001
I0621 22:19:49.905494 18138 solver.cpp:228] Iteration 9600, loss = 0.00205025
I0621 22:19:49.905534 18138 solver.cpp:244]     Train net output #0: loss = 0.00205032 (* 1 = 0.00205032 loss)
I0621 22:19:49.905542 18138 sgd_solver.cpp:106] Iteration 9600, lr = 0.001
I0621 22:20:01.963567 18138 solver.cpp:228] Iteration 9700, loss = 0.00173567
I0621 22:20:01.963606 18138 solver.cpp:244]     Train net output #0: loss = 0.00173573 (* 1 = 0.00173573 loss)
I0621 22:20:01.963614 18138 sgd_solver.cpp:106] Iteration 9700, lr = 0.001
I0621 22:20:14.022470 18138 solver.cpp:228] Iteration 9800, loss = 0.00468418
I0621 22:20:14.022511 18138 solver.cpp:244]     Train net output #0: loss = 0.00468425 (* 1 = 0.00468425 loss)
I0621 22:20:14.022519 18138 sgd_solver.cpp:106] Iteration 9800, lr = 0.001
I0621 22:20:26.043076 18138 solver.cpp:228] Iteration 9900, loss = 0.00772618
I0621 22:20:26.043115 18138 solver.cpp:244]     Train net output #0: loss = 0.00772625 (* 1 = 0.00772625 loss)
I0621 22:20:26.043124 18138 sgd_solver.cpp:106] Iteration 9900, lr = 0.001
I0621 22:20:37.993072 18138 solver.cpp:454] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel
I0621 22:20:38.087818 18138 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate
I0621 22:20:38.332872 18138 solver.cpp:337] Iteration 10000, Testing net (#0)
I0621 22:20:40.134519 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9909
I0621 22:20:40.134558 18138 solver.cpp:404]     Test net output #1: loss = 0.0580515 (* 1 = 0.0580515 loss)
I0621 22:20:40.252183 18138 solver.cpp:228] Iteration 10000, loss = 0.00814617
I0621 22:20:40.252228 18138 solver.cpp:244]     Train net output #0: loss = 0.00814624 (* 1 = 0.00814624 loss)
I0621 22:20:40.252236 18138 sgd_solver.cpp:106] Iteration 10000, lr = 0.001
I0621 22:20:52.327134 18138 solver.cpp:228] Iteration 10100, loss = 0.00843249
I0621 22:20:52.327178 18138 solver.cpp:244]     Train net output #0: loss = 0.00843255 (* 1 = 0.00843255 loss)
I0621 22:20:52.327186 18138 sgd_solver.cpp:106] Iteration 10100, lr = 0.001
I0621 22:21:04.384847 18138 solver.cpp:228] Iteration 10200, loss = 0.00338284
I0621 22:21:04.384888 18138 solver.cpp:244]     Train net output #0: loss = 0.00338291 (* 1 = 0.00338291 loss)
I0621 22:21:04.384897 18138 sgd_solver.cpp:106] Iteration 10200, lr = 0.001
I0621 22:21:16.461874 18138 solver.cpp:228] Iteration 10300, loss = 0.000169721
I0621 22:21:16.461915 18138 solver.cpp:244]     Train net output #0: loss = 0.000169796 (* 1 = 0.000169796 loss)
I0621 22:21:16.461923 18138 sgd_solver.cpp:106] Iteration 10300, lr = 0.001
I0621 22:21:28.289896 18138 solver.cpp:228] Iteration 10400, loss = 0.0425089
I0621 22:21:28.289940 18138 solver.cpp:244]     Train net output #0: loss = 0.042509 (* 1 = 0.042509 loss)
I0621 22:21:28.289948 18138 sgd_solver.cpp:106] Iteration 10400, lr = 0.001
I0621 22:21:39.915698 18138 solver.cpp:337] Iteration 10500, Testing net (#0)
I0621 22:21:41.593545 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9924
I0621 22:21:41.593583 18138 solver.cpp:404]     Test net output #1: loss = 0.048541 (* 1 = 0.048541 loss)
I0621 22:21:41.707273 18138 solver.cpp:228] Iteration 10500, loss = 0.000884949
I0621 22:21:41.707315 18138 solver.cpp:244]     Train net output #0: loss = 0.000885025 (* 1 = 0.000885025 loss)
I0621 22:21:41.707324 18138 sgd_solver.cpp:106] Iteration 10500, lr = 0.001
I0621 22:21:53.445932 18138 solver.cpp:228] Iteration 10600, loss = 0.0212373
I0621 22:21:53.445973 18138 solver.cpp:244]     Train net output #0: loss = 0.0212374 (* 1 = 0.0212374 loss)
I0621 22:21:53.445981 18138 sgd_solver.cpp:106] Iteration 10600, lr = 0.001
I0621 22:22:05.273737 18138 solver.cpp:228] Iteration 10700, loss = 0.0498665
I0621 22:22:05.273778 18138 solver.cpp:244]     Train net output #0: loss = 0.0498665 (* 1 = 0.0498665 loss)
I0621 22:22:05.273787 18138 sgd_solver.cpp:106] Iteration 10700, lr = 0.001
I0621 22:22:17.028534 18138 solver.cpp:228] Iteration 10800, loss = 0.0005916
I0621 22:22:17.028574 18138 solver.cpp:244]     Train net output #0: loss = 0.000591681 (* 1 = 0.000591681 loss)
I0621 22:22:17.028583 18138 sgd_solver.cpp:106] Iteration 10800, lr = 0.001
I0621 22:22:28.764070 18138 solver.cpp:228] Iteration 10900, loss = 0.000440677
I0621 22:22:28.764111 18138 solver.cpp:244]     Train net output #0: loss = 0.00044076 (* 1 = 0.00044076 loss)
I0621 22:22:28.764119 18138 sgd_solver.cpp:106] Iteration 10900, lr = 0.001
I0621 22:22:40.508795 18138 solver.cpp:337] Iteration 11000, Testing net (#0)
I0621 22:22:42.185691 18138 solver.cpp:404]     Test net output #0: accuracy = 0.9916
I0621 22:22:42.185729 18138 solver.cpp:404]     Test net output #1: loss = 0.0557694 (* 1 = 0.0557694 loss)
I0621 22:22:42.298230 18138 solver.cpp:228] Iteration 11000, loss = 0.027712
I0621 22:22:42.298276 18138 solver.cpp:244]     Train net output #0: loss = 0.0277121 (* 1 = 0.0277121 loss)
I0621 22:22:42.298285 18138 sgd_solver.cpp:106] Iteration 11000, lr = 0.001
